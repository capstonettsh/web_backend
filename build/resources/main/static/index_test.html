<!DOCTYPE html>
<html>
<head>
    <title>HumeAI Voice Chat</title>
    <style>
        body {
            font-family: Arial, sans-serif;
        }
        #messages {
            border: 1px solid #ccc;
            height: 300px;
            overflow-y: scroll;
            padding: 10px;
            margin-bottom: 10px;
        }
        #startButton, #stopButton {
            padding: 10px 20px;
        }
        .message {
            margin: 5px 0;
        }
        .user-message {
            text-align: right;
            color: blue;
        }
        .evi-message {
            text-align: left;
            color: green;
        }





    </style>
</head>
<body>
<h1>HumeAI Voice Chat</h1>
<div id="messages"></div>
<button id="startButton">Start Recording</button>
<button id="stopButton" disabled>Stop Recording</button>
<h1>Webcam Video Streaming</h1>
<video id="video" width="320" height="240" autoplay></video>
<br>
<button id="startVideo">Start Video</button>
<button id="stopVideo" disabled>Stop Video</button>

<script>
        const videoElement = document.getElementById('video');
        let mediaStream;
        const wsFacial = new WebSocket("ws://localhost:8080/v0/facial?sessionDateTime=" + encodeURIComponent(new Date().toISOString()));
        let captureInterval; // Reference to the setInterval timer

        // Establish WebSocket connection
        wsFacial.addEventListener('open', function() {
            console.log("Connected to facial websocket server");
            document.getElementById('startVideo').disabled = false;
        });

        wsFacial.addEventListener('close', function() {
            console.log("Disconnected from facial websocket server");
            // Clean up if necessary
            stopVideoStream();
        });

        wsFacial.addEventListener('error', function(event) {
            console.error("WebSocket error:", event);
        });

        // Start video stream
        document.getElementById('startVideo').addEventListener('click', async function() {
            try {
                // Access the webcam (video only)
                mediaStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
                videoElement.srcObject = mediaStream;
                videoElement.play();

                this.disabled = true;
                document.getElementById('stopVideo').disabled = false;

                // Start capturing and sending frames every 100ms
                captureInterval = setInterval(captureAndSendFrame, 3000); // 100ms interval

                console.log("Started capturing and sending frames every 100ms");
            } catch (error) {
                console.error('Error accessing webcam:', error);
            }
        });

        // Stop video stream
        document.getElementById('stopVideo').addEventListener('click', function() {
            stopVideoStream();
            this.disabled = true;
            document.getElementById('startVideo').disabled = false;
        });

        // Function to stop the video stream and clear the interval
        function stopVideoStream() {
            if (captureInterval) {
                clearInterval(captureInterval);
                captureInterval = null;
                console.log("Stopped capturing frames");
            }

            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
                console.log("Media stream stopped");
            }

            videoElement.srcObject = null;
        }

        // Function to capture and send a frame
        function captureAndSendFrame() {
            try {
                // Create a canvas to draw the video frame
                const canvas = document.createElement('canvas');
                canvas.width = videoElement.videoWidth || 640; // Fallback to 640 if metadata not loaded
                canvas.height = videoElement.videoHeight || 480; // Fallback to 480 if metadata not loaded

                const context = canvas.getContext('2d');
                context.drawImage(videoElement, 0, 0, canvas.width, canvas.height);

                // Convert the canvas to a compressed image format (JPEG)
                canvas.toBlob(blob => {
                    if (wsFacial.readyState === WebSocket.OPEN) {
                        console.log("sent");
                        wsFacial.send(blob);
                        console.log("sent1");
                    } else {
                        console.warn('WebSocket is not open. Unable to send frame.');
                    }
                }, 'image/jpeg', 0.7); // Adjust quality (0.0 - 1.0) as needed
            } catch (error) {
                console.error('Error capturing frame:', error);
            }
        }

        var audioContext;
        var mediaRecorder;
        var sessionDateTime = new Date().toISOString();
        var encodedSessionDateTime = encodeURIComponent(sessionDateTime);

        // Create WebSocket connections with sessionDateTime as query parameter
        var ws = new WebSocket("ws://localhost:8080/v0/chat?sessionDateTime=" + encodedSessionDateTime);

        ws.onopen = function() {
            console.log("Connected to server");
        };

        ws.onmessage = function(event) {
            if (typeof event.data === 'string') {
                // Parse the JSON message
                var message = JSON.parse(event.data);
                if (message.type === 'audio_output') {
                    // Extract the base64-encoded audio data
                    var base64Data = message.data;

                    // Decode the base64 string
                    var audioData = base64ToArrayBuffer(base64Data);

                    // Play the audio
                    playAudio(audioData);
                } else {
                    // Handle other message types if necessary
                    console.log("Received message:", message);
                }
            }
        };

        ws.onclose = function() {
            console.log("Disconnected from server");
        };

        document.getElementById('startButton').addEventListener('click', startRecording);
        document.getElementById('stopButton').addEventListener('click', stopRecording);

        function startRecording() {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            document.getElementById('startButton').disabled = true;
            document.getElementById('stopButton').disabled = false;

            navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });

                mediaRecorder.onstart = function() {
                    console.log('Recording started.');
                };

                mediaRecorder.ondataavailable = function(event) {
                    if (event.data.size > 0 && ws.readyState === WebSocket.OPEN) {
                        // Send the audio data to the backend
                        event.data.arrayBuffer().then(buffer => {
                            ws.send(buffer);
                        });
                    }
                };

                mediaRecorder.onstop = function() {
                    console.log('Recording stopped.');
                };

                mediaRecorder.start(100); // Collect data every 100ms
            })
            .catch(error => {
                console.error('Error accessing microphone:', error);
            });
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
            document.getElementById('startButton').disabled = false;
            document.getElementById('stopButton').disabled = true;
        }


        var audioQueue = [];
        var isPlaying = false;

        function playAudio(arrayBuffer) {
            // Add the audio data to the queue
            audioQueue.push(arrayBuffer);

            // If nothing is currently playing, start playing the next audio in the queue
            if (!isPlaying) {
                playNextAudio();
            }
        }

        function playNextAudio() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                return;
            }

            var arrayBuffer = audioQueue.shift(); // Get the next audio data from the queue
            isPlaying = true;

            audioContext.decodeAudioData(arrayBuffer, function(buffer) {
                var source = audioContext.createBufferSource();
                source.buffer = buffer;
                source.connect(audioContext.destination);
                source.start(0);

                // When the audio finishes playing, try to play the next one
                source.onended = function() {
                    isPlaying = false;
                    playNextAudio();
                };
            }, function(e) {
                console.error("Error decoding audio data:", e);
                // Ensure that even if there's an error, we attempt to play the next audio
                isPlaying = false;
                playNextAudio();
            });
        }

        // Helper function to decode base64 to ArrayBuffer
        function base64ToArrayBuffer(base64) {
            var binaryString = atob(base64);
            var len = binaryString.length;
            var bytes = new Uint8Array(len);
            for (var i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

</script>
</body>
</html>
